# To the success
<br>


### 컴파일러 vs 인터프리터? (메쉬코리아)

<details>
   <summary> 답안 보기 (👈 Click)</summary>
<br />
[참고: 쉽게 배우는 운영체제] 
   
+ 컴파일러는 소스코드를 컴퓨터가 실행할 수 있는 기계어로 번역한 후 한꺼번에 실행합니다. <br> 
  C 언어, 자바 등이 이 방식으로 프로그램을 실행합니다. <br> 
  
  인터프리터는 소스코드를 한 행씩 번역하여 실행합니다. 자바스크립트, 베이직 등이 이 방식으로 프로그램을 실행합니다. <br> 
  
  컴파일러를 사용하는 목적은 <br>
  (1) 오류 발견 <br>
  - 컴파일러의 첫 번째 목적은 소스코드에서 오류를 발견하여 실행 시 문제가 없도록 하는 것입니다. <br> 
    컴파일러는 오류를 찾기 위해 심벌 테이블을 사용합니다. <br> 
    심벌 테이블은 변수 선언부에 명시한 각 변수의 이름과 종류를 모아놓은 테이블로, <br>
    선언하지 않은 변수를 사용하지는 않았는지, 변수에 다른 종류의 데이터를 저장하지는 않았는지 알 수 있습니다. <br> 
  
  (2) 코드 최적화 <br>
  - 컴파일러의 두 번째 목적은 최적화입니다. [그림 7-5]에는 '당근 1개를 잘라서 볶는다'가 두 번 나오는데 <br> 
    이를 '당근 2개를 잘라서 볶는다'로 변경하면 작업을 줄일 수 있습니다. <br> 
    또한, 준비 재료에는 들어 있지만 요리에 사용하지 않은 '고추'를 삭제하여 불필요한 재료를 없앨 수 있습니다. <br> 
    이러한 과정을 거치면 레시피가 최적화됩니다. 소스코드도 마찬가지로 군더더기와 사용하지 않는 변수를 삭제하면 <br> 
    더욱 간결해져서 실행 속도가 빨라집니다. <br> 
    결론적으로 컴파일러는 실행하기 전에 코드를 점검하여 오류를 수정하고 최적화함으로써 작고 빠른 실행 파일을 만듭니다. <br> 
  
  컴파일러를 사용하는 프로그래밍 언어는 사용할 변수를 먼저 선언한 후 코드를 작성합니다. <br> 
  이것이 다소 번거롭게 느껴질 수도 있으나 변수 선언은 오류를 찾고 코드를 최적화하기 위해 반드시 필요한 작업입니다. <br> 
  [그림 7-5]의 (b)에서 보듯이 준비 재료에 없는 재료를 사용하거나, 준비 재료에 명시되어 있으나 실제로 사용되지 않는 것을 골라내려면 <br> 
  준비 재료, 즉 변수가 미리 선언되어야 합니다. <br> 
  
  컴파일러는 실행 전에 소스코드를 점검하여 오류를 수정하고 필요 없는 부분을 정리하여 최적화된 실행 파일을 만듭니다. <br> 
  그러나 인터프리터는 한 줄씩 위에서부터 아래로 실행되기 때문에 같은 일을 반복하는 경우나 필요 없는 변수를 확인할 수는 없습니다. <br>
  따라서 크고 복잡한 프로그램에는 컴파일러를 사용하고, 간단한 프로그램에는 인터프리터를 사용합니다. <br> 
  
  컴파일러를 사용하는 자바와 인터프리터를 사용하는 자바스크립트를 비교해보면 컴파일러와 인터프리터의 차이를 알 수 있습니다. <br> 
  주로 대형 프로그램에 사용되는 자바는 컴파일 방식의 언어이므로, 변수를 미리 선언해야 합니다. <br> 
  컴파일 과정에서 최적화된 실행 파일이 만들어지며, 이 실행 파일을 실행하여 결과를 얻습니다. <br> 
  반면, 자바스크립트는 인터프리터 방식의 언어이므로 변수를 미리 선언할 필요가 없으며, 소스코드가 한 줄씩 실행됩니다. <br> 
  자바스크립트는 웹 프로그램 같은 간단한 프로그램을 작성하거나 데이터베이스를 다른 응용 프로그램과 연결하는 코드를 작성할 때 사용합니다. <br>  
  
</details>

-----------------------


### 가상 메모리란? (헤이비트)

<details>
   <summary> 답안 보기 (👈 Click)</summary>
<br />
[참고: 쉽게 배우는 운영체제 p.378] 
   
+ 가상 메모리는 물리 메모리(실제 메모리)의 크기와 상관없이 메모리를 이용할 수 있도록 지원하는 기술입니다. <br> 
  프로그래머는 가상 메모리 덕분에 물리 메모리의 크기에 구애받지 않고 작업할 수 있는 커다란 작업 공간을 얻게 되는 셈입니다. <br> 
  이 장에서는 가상 메모리 시스템을 운영하는 메모리 관리자의 역할과 다양한 관리 기법을 살펴봅니다. <br> 
   
  컴퓨터마다 물리 메모리, 즉 실제 메모리의 크기가 다르다. <br>
  가상 메모리는 크기가 다른 물리 메모리에서 일관되게 프로세스를 실행할 수 있는 기술이다. <br> 
  이 절에서는 가상 메모리가 무엇인지, 그리고 어떻게 구현하는지를 살펴봅니다. <br> 
   
  메모리의 크기는 컴퓨터마다 다른데 운영체제가 물리 메모리의 크기에만 의존한다면 2GB의 메모리에서 동작하는 프로그램이 <br> 
  1GB의 메모리에서는 동작하지 않을 수 있습니다. <br> 
  프로그래머 또한 메모리 크기에 맞는 응용 프로그램만 개발해야 하는데, 실제로 메모리 크기만 고려하여 프로그래밍하기란 매우 어렵습니다. <br> 
  사용할 수 있는 배열의 개수가 한정되거나, 특정 변수에 접근할 수 없다는 제약은 프로그래머에게 큰 장벽입니다. <br>
   
  현대 메모리 관리의 가장 큰 특징은 물리 메모리의 크기와 프로세스가 올라갈 메모리의 위치를 신경쓰지 않고, 프로그래밍하도록 지원한다는 것입니다. <br> 
  이러한 메모리 시스템을 가상 메모리라고 부릅니다. <br> 
  가상 메모리는 물리 메모리의 크기와 상관없이 프로세스에 커다란 메모리 공간을 제공하는 기술입니다. <br> 
  프로세스는 운영체제가 어디에 있는지, 물리 메모리의 크기가 어느 정도인지 신경 쓰지 않고 메모리를 마음대로 사용할 수 있습니다. <br> 
   
  가상 메모리 시스템의 모든 프로세스는 물리 메모리와 별개로 자신이 메모리의 어느 위치에 있는지 상관없이 0번지부터 시작하는 연속된 메모리 공간을 가집니다. <br> 
  이는 7장에서 소개한 논리 주소와 유사하지만 한 가지 차이점이 있습니다. <br> 
  논리 주소는 물리 메모리의 주소 공간에 비례하고, 가상 주소는 물리 메모리 공간이 아닌 가상의 주소 공간을 가진다는 것입니다. <br> 
   
  [그림 8-2]는 가상 메모리의 구성을 나타낸 것입니다. 가상 메모리는 크게 프로세스가 바라보는 메모리 영역과 메모리 관리자가 바라보는 메모리 영역으로 나뉩니다. <br>
  
  이론적으로 가상 메모리는 무한대의 크기입니다. 그러나 실제로 가상 메모리의 최대 크기는 그 컴퓨터 시스템이 가진 물리 메모리의 최대 크기로 한정되며, <br> 
  7장에서 설명했듯이, CPU의 비트에 따라 결정됩니다. <br> 
  32bit CPU의 경우 32bit로 표현할 수 있는 최대값인 2^32-1(16진수로 FFFFFFFF), 즉, 약 4GB가 메모리의 최대 크기이고, 가상 메모리의 최대 크기도 약 4GB입니다. <br> 
   
  그런데 가상 메모리는 실제로 사용할 수 있는 최대 크기의 제약에도 불구하고, 어떻게 이론적으로 무한대의 크기가 있는 것처럼 구현할 수 있을까? <br> 
  예를 통해 살펴보자. <br> 
   
  32bit CPU의 최대 메모리 크기는 4GB입니다. 이 시스템에서 각각 4GB 주소 공간을 차지하는 10개의 프로세스를 동시에 실행하려면, <br>
  운영체제를 포함하여 적어도 40GB의 메모리가 필요합니다. <br> 
  이 경우 가상 메모리 시스템에서는 물리 메모리의 내용 중 일부를 하드디스크의 일부 공간, 즉 스왑 영역으로 옮깁니다. <br> 
  스왑 영역은 하드디스크에 존재하지만, 메모리 관리자가 관리하는 영역으로서 메모리의 일부이며, 가상 메모리의 구성 요소 중 하나입니다 <br> 
   
  메모리 관리자는 물리 메모리의 부족한 부분을 스왑 영역으로 보충합니다. <br> 
  즉, 물리 메모리가 꽉 찼을 때, 일부 프로세스를 스왑 영역으로 보내고(스왑 아웃), <br>
  몇 개의 프로세스가 작업을 마치면 스왑 영역에 있는 프로세스를 메모리로 가져옵니다. (스왑 인) <br> 
   
  가상 메모리의 크기 - 가상 메모리에서 메모리 관리자가 사용할 수 있는 메모리의 전체 크기는 물리 메모리(실제 메모리)와 <br>
  스왑 영역을 합한 크기입니다. <br> 
   
  가상 메모리 시스템에서 메모리 관리자는 물리 메모리와 스왑 영역을 합쳐서 프로세스가 사용하는 가상 주소를 실제 메모리의 물리 주소로 변환하는데, <br> 
  이러한 작업을 동적 주소 변환이라고 합니다. <br> 
  동적 주소 변환을 거치면 프로세스가 아무 제약 없이 사용자의 데이터를 물리 메모리에 배치할 수 있습니다. <br> 
  이 과정에서 메모리 관리자는 물리 메모리를 어떤 방법으로 나눌지, 사용자 프로세스를 어디에 배치할지, <br>
  부족한 물리 메모리를 어떻게 처리할지 등의 복잡한 문제를 처리합니다. <br> 
   
</details>

-----------------------


### Round Robin 스케줄링이란? (위메프)

<details>
   <summary> 답안 보기 (👈 Click)</summary>
<br />
[참고: 쉽게 배우는 운영체제 p.220] 
   
+ '순환 순서 방식'으로 번역되는 라운드 로빈 스케줄링은 한 프로세스가 할당받은 시간(타임 슬라이스)동안 작업을 하다가 <br> 
   작업을 완료하지 못하면 준비 큐의 맨 뒤로 가서 자기 차례를 기다리는 방식입니다. <br> 
   선점형 알고리즘 중 가장 단순하고 대표적인 방식으로, 프로세스들이 작업을 완료할 때까지 계속 순환하면서 실행됩니다. <br> 
   
   라운드 로빈 스케줄링은 FCFS 스케줄링과 유사한데, 차이점은 각 프로세스마다 CPU를 사용할 수 있는 최대 시간, <br>
   즉, 타임 슬라이스가 있다는 것입니다. <br> 
   프로세스는 자신에게 주어진 타임 슬라이스 동안만 작업할 수 있으며, 작업이 다 끝나지 않으면 큐의 뒤쪽에 다시 삽입됩니다. <br> 
   라운드 로빈 스케줄링은 우선순위가 적용되지 않은 가장 단순한 선점형 스케줄링 방식입니다. <br> 
   
</details>

-----------------------


### 선점형 스케줄링 방식이란 무엇인가? (위메프)

<details>
   <summary> 답안 보기 (👈 Click)</summary>
<br />
[참고: 쉽게 배우는 운영체제 p.212] 
   
+ 스케줄링 알고리즘은 크게 비선점형 알고리즘과 선점형 알고리즘으로 나뉩니다. <br> 
  비선점형 알고리즘은 프로세스가 CPU를 할당받으면 작업이 끝날 때까지 CPU를 놓지 않기 때문에, <br>
  효율이 떨어져서 지금은 거의 사용되지 않습니다. <br> 
  
  선점형 알고리즘은 시분할 시스템을 고려하여 만들어진 알고리즘으로, 어떤 프로세스가 CPU를 할당 받아 실행 중이라도 <br>
  운영체제가 CPU를 강제로 빼앗을 수 있습니다. <br> 
</details>

-----------------------

### Round Robin 스케줄링의 성능은 어떠한가? (위메프)

<details>
   <summary> 답안 보기 (👈 Click)</summary>
<br />
[참고: 쉽게 배우는 운영체제 p.221] 
   
+ 타임 슬라이스가 10밀리초인 시스템에서 앞의 [표 4-3]과 같은 프로세스가 실행될 때, 라운드 로빈 스케줄링의 평균 대기 시간을 계산해봅니다. <br> 
  프로세스 P1은 도착하자마자 실행되므로, 대기 시간이 0밀리초입니다. <br> 
  P1은 자신에게 주어진 작업 시간인 10밀리초 동안 실행된 후 큐의 맨 뒤로 이동합니다. <br> 
  프로세스 P2는 3밀리초 후에 도착하여 7밀리초를 기다렸다 10밀리초 동안 실행되고 나서 큐의 맨 뒤로 이동합니다. <br> 
  프로세스 P3은 6밀리초 후에 도착하여 14밀리초를 기다렸다 9밀리초 동안 실행되어 작업을 마칩니다. <br> 
   
  프로세스 P1은 29밀리초 후에 작업을 다시 시작합니다. 앞에서 10밀리초 동안 실행되었기 때문에, <br>
  실제 대기 시간은 19밀리초입니다. 프로세스 P1이 10밀리초 동안 실행된 후 큐의 맨 뒤로 이동하면 <br> 
  P2가 8밀리초 동안 실행되어 남은 작업을 마치며, 마지막으로 P1이 10밀리초 동안 실행되어 작업을 마칩니다. <br> 
   
  이 세 프로세스의 총 대기 시간은 0(P1)+7(P2)+14(P3)+19(P1)+19(P2)+8(P1) = 67밀리초이고, 평균 대기 시간은 67 / 3 = 22.33밀리초입니다. <br> 
  라운드 로빈 스케줄링 같은 선점형 방식에서는 프로세스가 CPU를 일정 시간 동안 사용한 후 다른 프로세스에 주어야 하기 때문에 <br>
  앞의 긴 작업을 무작정 기다리는 콘베이 효과가 줄어듭니다. <br> 
   
</details>

-----------------------

